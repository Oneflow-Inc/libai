[03/30 11:28:49] libai INFO: Rank of current process: 0. World size: 1
[03/30 11:28:49] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 11:28:49] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 11:28:49] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 11:28:49] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 11:28:50] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.054 seconds
[03/30 11:28:50] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.055 seconds
[03/30 11:28:52] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008338 seconds
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 11:28:52] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:28:52] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:28:52] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 11:28:52] libai INFO: > Start building model...
[03/30 11:28:52] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 11:28:52] libai INFO: >>> done with building model. Building time: 0.145 seconds
[03/30 11:28:52] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 11:28:53] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 11:29:18] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 4  total_loss: 10.86  data_time: 0.0014 s/iter  lr: 5.00e-05  
[03/30 11:29:44] lb.utils.events INFO:  eta: 100 days, 0:25:31  iteration: 1/335008  consumed_samples: 8  total_loss: 10.08  data_time: 0.0010 s/iter  lr: 5.00e-05  
[03/30 11:30:10] lb.utils.events INFO:  eta: 100 days, 2:37:28  iteration: 2/335008  consumed_samples: 12  total_loss: 9.44  time: 25.8189 s/iter  data_time: 0.0011 s/iter total_throughput: 0.15 samples/s lr: 5.00e-05  
[03/30 11:30:35] lb.utils.events INFO:  eta: 99 days, 6:11:35  iteration: 3/335008  consumed_samples: 16  total_loss: 9.374  time: 25.5994 s/iter  data_time: 0.0009 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:31:01] lb.utils.events INFO:  eta: 99 days, 21:40:02  iteration: 4/335008  consumed_samples: 20  total_loss: 9.307  time: 25.6548 s/iter  data_time: 0.0010 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:31:27] lb.utils.events INFO:  eta: 99 days, 18:03:38  iteration: 5/335008  consumed_samples: 24  total_loss: 9.212  time: 25.6632 s/iter  data_time: 0.0009 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:31:53] lb.utils.events INFO:  eta: 99 days, 18:24:32  iteration: 6/335008  consumed_samples: 28  total_loss: 9.117  time: 25.6768 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:32:18] lb.utils.events INFO:  eta: 99 days, 20:01:26  iteration: 7/335008  consumed_samples: 32  total_loss: 9.093  time: 25.7183 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:32:44] lb.utils.events INFO:  eta: 99 days, 18:23:41  iteration: 8/335008  consumed_samples: 36  total_loss: 9.069  time: 25.7046 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:33:10] lb.utils.events INFO:  eta: 99 days, 16:24:36  iteration: 9/335008  consumed_samples: 40  total_loss: 8.982  time: 25.6782 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:33:35] lb.utils.events INFO:  eta: 99 days, 14:25:31  iteration: 10/335008  consumed_samples: 44  total_loss: 8.896  time: 25.6656 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:34:01] lb.utils.events INFO:  eta: 99 days, 16:23:44  iteration: 11/335008  consumed_samples: 48  total_loss: 8.853  time: 25.6755 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:34:27] lb.utils.events INFO:  eta: 99 days, 17:39:35  iteration: 12/335008  consumed_samples: 52  total_loss: 8.811  time: 25.6799 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:34:53] lb.utils.events INFO:  eta: 99 days, 18:00:21  iteration: 13/335008  consumed_samples: 56  total_loss: 8.789  time: 25.6990 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:35:18] lb.utils.events INFO:  eta: 99 days, 18:21:06  iteration: 14/335008  consumed_samples: 60  total_loss: 8.768  time: 25.7027 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:35:44] lb.utils.events INFO:  eta: 99 days, 17:59:29  iteration: 15/335008  consumed_samples: 64  total_loss: 8.736  time: 25.7000 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:36:10] lb.utils.events INFO:  eta: 99 days, 18:20:15  iteration: 16/335008  consumed_samples: 68  total_loss: 8.704  time: 25.7059 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:36:36] lb.utils.events INFO:  eta: 99 days, 19:02:25  iteration: 17/335008  consumed_samples: 72  total_loss: 8.693  time: 25.7103 s/iter  data_time: 0.0008 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 11:37:47] libai INFO: Rank of current process: 0. World size: 1
[03/30 11:37:47] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 11:37:47] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 11:37:47] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 11:37:47] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 11:37:47] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.053 seconds
[03/30 11:37:47] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.054 seconds
[03/30 11:37:49] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007539 seconds
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 11:37:49] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:37:49] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:37:50] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 11:37:50] libai INFO: > Start building model...
[03/30 11:37:50] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 11:37:50] libai INFO: >>> done with building model. Building time: 0.155 seconds
[03/30 11:37:50] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 11:37:51] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 11:37:51] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 11:37:56] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error

[03/30 11:37:56] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/30 11:49:16] libai INFO: Rank of current process: 0. World size: 1
[03/30 11:49:16] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 11:49:16] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m0[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 11:49:16] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 11:49:16] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 11:49:16] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.045 seconds
[03/30 11:49:16] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.046 seconds
[03/30 11:49:18] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008186 seconds
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 11:49:18] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:49:18] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:49:19] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 11:49:19] libai INFO: > Start building model...
[03/30 11:49:19] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 11:49:19] libai INFO: >>> done with building model. Building time: 0.157 seconds
[03/30 11:49:19] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 11:49:19] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 11:49:19] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 11:49:20] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 11:49:20] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 11:49:25] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error

[03/30 11:49:25] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/30 11:49:48] libai INFO: Rank of current process: 0. World size: 1
[03/30 11:49:48] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 11:49:48] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 11:49:48] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 11:49:48] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 11:49:48] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.044 seconds
[03/30 11:49:48] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.045 seconds
[03/30 11:49:50] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.006787 seconds
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 11:49:50] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.003 seconds
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 11:49:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 11:49:50] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 11:49:50] libai INFO: > Start building model...
[03/30 11:49:50] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 11:49:50] libai INFO: >>> done with building model. Building time: 0.154 seconds
[03/30 11:49:50] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 11:49:50] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 11:49:50] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 11:49:51] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 11:49:51] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 11:49:56] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error

[03/30 11:49:56] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/30 15:40:54] libai INFO: Rank of current process: 0. World size: 1
[03/30 15:40:54] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 15:40:54] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 15:40:54] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 15:40:54] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 15:40:54] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.050 seconds
[03/30 15:40:54] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.051 seconds
[03/30 15:40:56] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008802 seconds
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 15:40:56] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.006 seconds
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 15:40:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 15:40:56] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 15:40:56] libai INFO: > Start building model...
[03/30 15:40:56] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 15:40:56] libai INFO: >>> done with building model. Building time: 0.169 seconds
[03/30 15:40:56] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 15:40:56] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 15:40:56] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 15:40:58] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 15:40:58] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 15:41:03] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/30 15:41:03] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/30 16:06:54] libai INFO: Rank of current process: 0. World size: 1
[03/30 16:06:54] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 16:06:54] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 16:06:54] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 16:06:54] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 16:06:54] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.052 seconds
[03/30 16:06:54] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.053 seconds
[03/30 16:06:56] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.006865 seconds
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 16:06:56] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:06:56] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:06:56] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 16:06:56] libai INFO: > Start building model...
[03/30 16:06:56] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 16:06:56] libai INFO: >>> done with building model. Building time: 0.135 seconds
[03/30 16:06:56] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 16:06:57] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 16:07:23] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 4  total_loss: 10.86  data_time: 0.0028 s/iter  lr: 5.00e-05  
[03/30 16:07:48] lb.utils.events INFO:  eta: 99 days, 12:07:57  iteration: 1/335008  consumed_samples: 8  total_loss: 10.08  data_time: 0.0016 s/iter  lr: 5.00e-05  
[03/30 16:08:14] lb.utils.events INFO:  eta: 99 days, 18:10:44  iteration: 2/335008  consumed_samples: 12  total_loss: 9.44  time: 25.7281 s/iter  data_time: 0.0013 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 16:10:06] libai INFO: Rank of current process: 0. World size: 1
[03/30 16:10:06] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 16:10:06] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 16:10:06] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 16:10:06] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 16:10:06] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.052 seconds
[03/30 16:10:06] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.053 seconds
[03/30 16:10:08] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007809 seconds
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 16:10:08] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:10:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:10:08] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 16:10:08] libai INFO: > Start building model...
[03/30 16:10:08] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 16:10:08] libai INFO: >>> done with building model. Building time: 0.156 seconds
[03/30 16:10:08] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 16:10:09] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 16:10:35] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 4  total_loss: 10.86  data_time: 0.0018 s/iter  lr: 5.00e-05  
[03/30 16:11:01] lb.utils.events INFO:  eta: 99 days, 11:08:04  iteration: 1/335008  consumed_samples: 8  total_loss: 10.08  data_time: 0.0014 s/iter  lr: 5.00e-05  
[03/30 16:11:26] lb.utils.events INFO:  eta: 99 days, 13:30:23  iteration: 2/335008  consumed_samples: 12  total_loss: 9.44  time: 25.6779 s/iter  data_time: 0.0012 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 16:11:52] lb.utils.events INFO:  eta: 99 days, 5:53:49  iteration: 3/335008  consumed_samples: 16  total_loss: 9.374  time: 25.5962 s/iter  data_time: 0.0010 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 16:12:17] libai INFO: Rank of current process: 0. World size: 1
[03/30 16:12:17] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 16:12:17] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 16:12:17] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 16:12:17] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 16:12:18] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.051 seconds
[03/30 16:12:18] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.052 seconds
[03/30 16:12:19] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007111 seconds
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 16:12:19] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 16:12:19] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 16:12:19] lb.data.datasets.gpt_dataset INFO:  > last epoch number of samples (977) is smaller than 80% of number of samples per epoch (4511), setting separate_last_epoch to True
[03/30 16:12:19] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.010740
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.001255
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 9023) and [9023, 13535) ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000525
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_doc_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_sample_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > only one epoch required, setting separate_last_epoch to False
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.003128
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.000350
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 4511) and [4511, 4511) ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000232
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_doc_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_sample_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > only one epoch required, setting separate_last_epoch to False
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.003130
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.000328
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 4511) and [4511, 4511) ...
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000229
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_doc_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_sample_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_shuffle_idx.npy
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 16:12:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 16:12:20] lb.engine.default INFO: Auto-scaling the config to train.train_iter=446655, train.warmup_iter=0
[03/30 16:12:20] libai INFO: > Start building model...
[03/30 16:12:20] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 16:12:20] libai INFO: >>> done with building model. Building time: 0.153 seconds
[03/30 16:12:20] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 16:12:20] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 16:12:20] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 16:12:21] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 16:12:21] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 17:28:10] libai INFO: Rank of current process: 0. World size: 1
[03/30 17:28:10] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 17:28:10] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;197m=[39m[38;5;141m1[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 17:28:10] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 17:28:10] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 17:28:10] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.094 seconds
[03/30 17:28:10] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.095 seconds
[03/30 17:28:12] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007207 seconds
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 17:28:12] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_doc_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_sample_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_doc_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_sample_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_doc_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_sample_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:28:12] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:28:12] lb.engine.default INFO: Auto-scaling the config to train.train_iter=446655, train.warmup_iter=0
[03/30 17:28:12] libai INFO: > Start building model...
[03/30 17:28:12] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 17:28:12] libai INFO: >>> done with building model. Building time: 0.153 seconds
[03/30 17:28:12] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 17:28:12] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 17:28:12] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 17:28:14] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 17:28:14] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 17:28:21] lb.utils.events INFO:  iteration: 0/446655  consumed_samples: 1  total_loss: 11.33  data_time: 0.0009 s/iter  lr: 5.00e-05  
[03/30 17:28:27] lb.utils.events INFO:  eta: 33 days, 6:54:54  iteration: 1/446655  consumed_samples: 2  total_loss: 11.34  data_time: 0.0016 s/iter  lr: 5.00e-05  
[03/30 17:28:34] lb.utils.events INFO:  eta: 33 days, 3:04:22  iteration: 2/446655  consumed_samples: 3  total_loss: 11.33  time: 6.4083 s/iter  data_time: 0.0029 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:28:40] lb.utils.events INFO:  eta: 33 days, 3:14:30  iteration: 3/446655  consumed_samples: 4  total_loss: 11.34  time: 6.4096 s/iter  data_time: 0.0024 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:28:46] lb.utils.events INFO:  eta: 33 days, 3:19:03  iteration: 4/446655  consumed_samples: 5  total_loss: 11.36  time: 6.4098 s/iter  data_time: 0.0021 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:28:53] lb.utils.events INFO:  eta: 33 days, 3:20:56  iteration: 5/446655  consumed_samples: 6  total_loss: 11.35  time: 6.4101 s/iter  data_time: 0.0020 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:28:59] lb.utils.events INFO:  eta: 33 days, 3:18:50  iteration: 6/446655  consumed_samples: 7  total_loss: 11.34  time: 6.4101 s/iter  data_time: 0.0020 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:29:06] lb.utils.events INFO:  eta: 33 days, 3:17:35  iteration: 7/446655  consumed_samples: 8  total_loss: 11.34  time: 6.4013 s/iter  data_time: 0.0018 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:32:57] libai INFO: Rank of current process: 0. World size: 1
[03/30 17:32:57] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 17:32:57] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m2[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 17:32:57] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 17:32:57] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 17:32:57] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.056 seconds
[03/30 17:32:57] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.057 seconds
[03/30 17:32:59] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007043 seconds
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 17:32:59] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > last epoch number of samples (1953) is smaller than 80% of number of samples per epoch (4511), setting separate_last_epoch to True
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.019319
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.001643
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 18047) and [18047, 22559) ...
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000756
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_20000ns_1024sl_1234s_doc_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_20000ns_1024sl_1234s_sample_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_20000ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of samples: 22560
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 5
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_doc_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_sample_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_doc_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_sample_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:32:59] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:32:59] lb.engine.default INFO: Auto-scaling the config to train.train_iter=372224, train.warmup_iter=0
[03/30 17:32:59] libai INFO: > Start building model...
[03/30 17:32:59] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 17:32:59] libai INFO: >>> done with building model. Building time: 0.156 seconds
[03/30 17:32:59] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 17:33:00] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 17:33:00] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 17:33:06] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/30 17:33:06] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/30 17:33:37] libai INFO: Rank of current process: 0. World size: 1
[03/30 17:33:37] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 17:33:37] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 17:33:37] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 17:33:37] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 17:33:37] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.080 seconds
[03/30 17:33:37] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.080 seconds
[03/30 17:33:39] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.006754 seconds
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 17:33:39] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_doc_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_sample_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_10000ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_doc_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_sample_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_750ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_doc_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_sample_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_250ns_1024sl_1234s_shuffle_idx.npy
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 17:33:39] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 17:33:39] lb.engine.default INFO: Auto-scaling the config to train.train_iter=446655, train.warmup_iter=0
[03/30 17:33:39] libai INFO: > Start building model...
[03/30 17:33:39] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 17:33:39] libai INFO: >>> done with building model. Building time: 0.161 seconds
[03/30 17:33:39] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 17:33:40] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 17:33:40] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 17:33:47] lb.utils.events INFO:  iteration: 0/446655  consumed_samples: 1  total_loss: 11.33  data_time: 0.0012 s/iter  lr: 5.00e-05  
[03/30 17:33:53] lb.utils.events INFO:  eta: 33 days, 2:28:50  iteration: 1/446655  consumed_samples: 2  total_loss: 11.34  data_time: 0.0011 s/iter  lr: 5.00e-05  
[03/30 17:33:59] lb.utils.events INFO:  eta: 33 days, 1:36:38  iteration: 2/446655  consumed_samples: 3  total_loss: 11.33  time: 6.3965 s/iter  data_time: 0.0011 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:06] lb.utils.events INFO:  eta: 33 days, 1:55:18  iteration: 3/446655  consumed_samples: 4  total_loss: 11.34  time: 6.3990 s/iter  data_time: 0.0012 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:12] lb.utils.events INFO:  eta: 33 days, 2:13:58  iteration: 4/446655  consumed_samples: 5  total_loss: 11.36  time: 6.4007 s/iter  data_time: 0.0013 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:19] lb.utils.events INFO:  eta: 33 days, 1:55:05  iteration: 5/446655  consumed_samples: 6  total_loss: 11.35  time: 6.3991 s/iter  data_time: 0.0013 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:25] lb.utils.events INFO:  eta: 33 days, 2:13:45  iteration: 6/446655  consumed_samples: 7  total_loss: 11.34  time: 6.4000 s/iter  data_time: 0.0012 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:31] lb.utils.events INFO:  eta: 33 days, 2:07:00  iteration: 7/446655  consumed_samples: 8  total_loss: 11.34  time: 6.4000 s/iter  data_time: 0.0012 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:38] lb.utils.events INFO:  eta: 33 days, 2:00:16  iteration: 8/446655  consumed_samples: 9  total_loss: 11.34  time: 6.3995 s/iter  data_time: 0.0014 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:44] lb.utils.events INFO:  eta: 33 days, 1:55:06  iteration: 9/446655  consumed_samples: 10  total_loss: 11.34  time: 6.3994 s/iter  data_time: 0.0015 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:51] lb.utils.events INFO:  eta: 33 days, 1:49:55  iteration: 10/446655  consumed_samples: 11  total_loss: 11.34  time: 6.3990 s/iter  data_time: 0.0015 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:34:57] lb.utils.events INFO:  eta: 33 days, 1:54:06  iteration: 11/446655  consumed_samples: 12  total_loss: 11.34  time: 6.3990 s/iter  data_time: 0.0015 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:03] lb.utils.events INFO:  eta: 33 days, 1:49:42  iteration: 12/446655  consumed_samples: 13  total_loss: 11.33  time: 6.3988 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:10] lb.utils.events INFO:  eta: 33 days, 1:53:53  iteration: 13/446655  consumed_samples: 14  total_loss: 11.33  time: 6.3991 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:16] lb.utils.events INFO:  eta: 33 days, 1:55:44  iteration: 14/446655  consumed_samples: 15  total_loss: 11.33  time: 6.3991 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:23] lb.utils.events INFO:  eta: 33 days, 1:52:31  iteration: 15/446655  consumed_samples: 16  total_loss: 11.33  time: 6.3990 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:29] lb.utils.events INFO:  eta: 33 days, 1:55:32  iteration: 16/446655  consumed_samples: 17  total_loss: 11.33  time: 6.3992 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:35] lb.utils.events INFO:  eta: 33 days, 1:52:18  iteration: 17/446655  consumed_samples: 18  total_loss: 11.33  time: 6.3990 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:42] lb.utils.events INFO:  eta: 33 days, 1:55:19  iteration: 18/446655  consumed_samples: 19  total_loss: 11.33  time: 6.3992 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:48] lb.utils.events INFO:  eta: 33 days, 1:56:22  iteration: 19/446655  consumed_samples: 20  total_loss: 11.33  time: 6.3993 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:35:55] lb.utils.events INFO:  eta: 33 days, 1:55:06  iteration: 20/446655  consumed_samples: 21  total_loss: 11.33  time: 6.3993 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:01] lb.utils.events INFO:  eta: 33 days, 1:55:02  iteration: 21/446655  consumed_samples: 22  total_loss: 11.33  time: 6.3993 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:07] lb.utils.events INFO:  eta: 33 days, 1:54:59  iteration: 22/446655  consumed_samples: 23  total_loss: 11.33  time: 6.3993 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:14] lb.utils.events INFO:  eta: 33 days, 1:54:56  iteration: 23/446655  consumed_samples: 24  total_loss: 11.33  time: 6.3993 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:20] lb.utils.events INFO:  eta: 33 days, 1:54:46  iteration: 24/446655  consumed_samples: 25  total_loss: 11.33  time: 6.3992 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:27] lb.utils.events INFO:  eta: 33 days, 1:54:37  iteration: 25/446655  consumed_samples: 26  total_loss: 11.33  time: 6.3990 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:33] lb.utils.events INFO:  eta: 33 days, 1:54:28  iteration: 26/446655  consumed_samples: 27  total_loss: 11.33  time: 6.3989 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:39] lb.utils.events INFO:  eta: 33 days, 1:53:04  iteration: 27/446655  consumed_samples: 28  total_loss: 11.33  time: 6.3989 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:46] lb.utils.events INFO:  eta: 33 days, 1:51:41  iteration: 28/446655  consumed_samples: 29  total_loss: 11.33  time: 6.3988 s/iter  data_time: 0.0017 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 17:36:52] lb.utils.events INFO:  eta: 33 days, 1:50:08  iteration: 29/446655  consumed_samples: 30  total_loss: 11.33  time: 6.3987 s/iter  data_time: 0.0016 s/iter total_throughput: 0.16 samples/s lr: 5.00e-05  
[03/30 18:18:17] libai INFO: Rank of current process: 0. World size: 4
[03/30 18:18:17] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/30 18:18:17] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/30 18:18:17] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/30 18:18:17] lb.engine.default INFO: > compiling dataset index builder ...
[03/30 18:18:17] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.088 seconds
[03/30 18:18:17] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.089 seconds
[03/30 18:18:19] lb.engine.default INFO: Prepare training, validating, testing set
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007127 seconds
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/30 18:18:19] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > last epoch number of samples (2084) is smaller than 80% of number of samples per epoch (4511), setting separate_last_epoch to True
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.142318
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.008270
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 157916) and [157916, 162428) ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.004275
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > last epoch number of samples (2977) is smaller than 80% of number of samples per epoch (4511), setting separate_last_epoch to True
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.010095
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.000795
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 9023) and [9023, 13535) ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000490
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > WARNING: could not find index map files, building the indices on rank 0 ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > only one epoch required, setting separate_last_epoch to False
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save doc-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save doc-idx mapping (seconds): 0.003151
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO: start to build and save sample-idx mapping ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save sample-idx mapping (seconds): 0.000337
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > building shuffle index with split [0, 4511) and [4511, 4511) ...
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > elapsed time to build and save shuffle-idx mapping (seconds): 0.000237
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/30 18:18:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/30 18:18:19] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/30 18:18:20] libai INFO: > Start building model...
[03/30 18:18:25] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/30 18:18:25] libai INFO: >>> done with building model. Building time: 5.322 seconds
[03/30 18:18:25] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/30 18:18:25] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 18:18:25] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/30 18:18:26] lb.engine.trainer INFO: Starting training from iteration 0
[03/30 18:18:26] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/30 18:18:35] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/30 18:18:35] lb.engine.hooks INFO: Total training time: 0:00:08 (0:00:00 on hooks)
[03/31 14:31:38] libai INFO: Rank of current process: 0. World size: 1
[03/31 14:31:38] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:31:38] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:31:38] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:31:38] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:31:38] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.050 seconds
[03/31 14:31:38] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.051 seconds
[03/31 14:31:40] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007057 seconds
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:31:40] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:31:40] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:31:40] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:31:40] libai INFO: > Start building model...
[03/31 14:31:41] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/31 14:31:41] libai INFO: >>> done with building model. Building time: 0.162 seconds
[03/31 14:31:41] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/31 14:31:41] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:31:41] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:31:42] lb.engine.trainer INFO: Starting training from iteration 0
[03/31 14:31:42] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/31 14:31:48] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/31 14:31:48] lb.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[03/31 14:32:17] libai INFO: Rank of current process: 0. World size: 4
[03/31 14:32:17] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:32:17] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:32:17] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:32:17] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:32:17] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.043 seconds
[03/31 14:32:17] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.044 seconds
[03/31 14:32:19] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.006932 seconds
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:32:19] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.010 seconds
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:32:19] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:32:20] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:32:20] libai INFO: > Start building model...
[03/31 14:40:48] libai INFO: Rank of current process: 0. World size: 4
[03/31 14:40:48] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:40:48] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:40:48] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:40:48] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:40:48] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.048 seconds
[03/31 14:40:48] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.049 seconds
[03/31 14:40:50] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007409 seconds
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:40:50] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.013 seconds
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:40:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:40:50] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:40:50] libai INFO: > Start building model...
[03/31 14:40:51] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/31 14:40:51] libai INFO: >>> done with building model. Building time: 0.843 seconds
[03/31 14:40:51] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/31 14:40:51] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:40:51] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:40:52] lb.engine.trainer INFO: Starting training from iteration 0
[03/31 14:40:52] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/31 14:41:01] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/31 14:41:01] lb.engine.hooks INFO: Total training time: 0:00:08 (0:00:00 on hooks)
[03/31 14:54:05] libai INFO: Rank of current process: 0. World size: 4
[03/31 14:54:05] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:54:06] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:54:06] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:54:06] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:54:06] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.056 seconds
[03/31 14:54:06] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.058 seconds
[03/31 14:54:08] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.009007 seconds
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:54:08] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.013 seconds
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:54:08] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:54:08] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:54:08] libai INFO: > Start building model...
[03/31 14:54:09] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/31 14:54:09] libai INFO: >>> done with building model. Building time: 0.872 seconds
[03/31 14:54:09] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/31 14:54:09] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:54:09] lb.engine.default INFO: Graph debug mode on, automatically output debug info.
[03/31 14:54:10] lb.engine.trainer INFO: Starting training from iteration 0
[03/31 14:54:10] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/31 14:54:19] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1166, in finish_compile_and_init_runtime
    self._c_nn_graph.init_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: MluDevice::Alloc error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in Allocate
    device->Alloc(options, &ptr, size)
Error Type: oneflow.ErrorProto.runtime_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/memory/memory_allocator.cpp", line 50, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/31 14:54:19] lb.engine.hooks INFO: Total training time: 0:00:09 (0:00:00 on hooks)
[03/31 14:57:13] libai INFO: Rank of current process: 0. World size: 4
[03/31 14:57:13] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:57:14] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:57:14] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:57:14] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:57:14] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.056 seconds
[03/31 14:57:14] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.058 seconds
[03/31 14:57:16] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008085 seconds
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:57:16] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.002 seconds
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.002 seconds
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:57:16] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:57:16] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:57:16] libai INFO: > Start building model...
[03/31 14:57:17] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/31 14:57:17] libai INFO: >>> done with building model. Building time: 0.885 seconds
[03/31 14:57:17] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/31 14:57:18] lb.engine.trainer INFO: Starting training from iteration 0
[03/31 14:57:47] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 16  total_loss: 10.86  data_time: 0.0064 s/iter  lr: 5.00e-05  
[03/31 14:59:32] libai INFO: Rank of current process: 0. World size: 4
[03/31 14:59:32] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/31 14:59:32] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/31 14:59:33] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/31 14:59:33] lb.engine.default INFO: > compiling dataset index builder ...
[03/31 14:59:33] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.088 seconds
[03/31 14:59:33] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.090 seconds
[03/31 14:59:35] lb.engine.default INFO: Prepare training, validating, testing set
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008213 seconds
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/31 14:59:35] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_doc_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_sample_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_160000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.011 seconds
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of samples: 162429
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 36
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_doc_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_sample_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_12000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of samples: 13536
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 3
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_doc_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_sample_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_4000ns_1024sl_1234s_shuffle_idx.npy
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/31 14:59:35] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/31 14:59:35] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/31 14:59:35] libai INFO: > Start building model...
[03/31 14:59:36] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/31 14:59:36] libai INFO: >>> done with building model. Building time: 0.831 seconds
[03/31 14:59:36] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/31 14:59:37] lb.engine.trainer INFO: Starting training from iteration 0
[03/31 15:00:06] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 16  total_loss: 10.86  data_time: 0.0058 s/iter  lr: 5.00e-05  
