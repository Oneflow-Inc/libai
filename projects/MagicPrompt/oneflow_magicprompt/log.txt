[03/28 10:45:49] libai INFO: Rank of current process: 0. World size: 1
[03/28 10:45:49] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 10:45:49] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 10:45:49] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 10:45:49] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 10:45:49] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.052 seconds
[03/28 10:45:49] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.053 seconds
[03/28 10:45:51] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.009791 seconds
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 10:45:51] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.006 seconds
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 10:45:51] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 10:45:51] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 10:45:51] libai INFO: > Start building model...
[03/28 10:45:51] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 10:45:51] libai INFO: >>> done with building model. Building time: 0.161 seconds
[03/28 10:45:51] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 10:45:53] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 10:45:53] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 10:45:59] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: model.GPT_model.transformer.layers.11.mlp.activation_func-scalar_pow_grad-605
 op_type_name: scalar_pow_grad
 DeviceType_Name: kMLU
 DataType_Name of dy_0: kFloat
 DataType_Name of x_0: kFloat
 DataType_Name of dx_0: kFloat
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name File "/home/zhangxiaoyu/libai/libai/models/utils/graph_base.py", line 107, in build, source < losses.backward() >; File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step, source < loss_dict = self.graph(**data) >; ... 5 more

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 10:45:59] lb.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[03/28 16:17:43] libai INFO: Rank of current process: 0. World size: 1
[03/28 16:17:43] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 16:17:43] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 16:17:43] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 16:17:43] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 16:17:43] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.042 seconds
[03/28 16:17:43] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.043 seconds
[03/28 16:17:46] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.010023 seconds
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 16:17:46] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.007 seconds
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:17:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:17:46] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 16:17:46] libai INFO: > Start building model...
[03/28 16:17:46] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 16:17:46] libai INFO: >>> done with building model. Building time: 0.208 seconds
[03/28 16:17:46] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 16:17:47] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 16:17:47] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 16:17:54] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: System-ClipGradient-GlobalNorm-MultiReduceSumPowAbs-423
 op_type_name: multi_reduce_sum_pow_abs
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of x_1: kFloat
 DataType_Name of x_2: kFloat
 DataType_Name of x_3: kFloat
 DataType_Name of x_4: kFloat
 DataType_Name of x_5: kFloat
 DataType_Name of x_6: kFloat
 DataType_Name of x_7: kFloat
 DataType_Name of x_8: kFloat
 DataType_Name of x_9: kFloat
 DataType_Name of x_10: kFloat
 DataType_Name of x_11: kFloat
 DataType_Name of x_12: kFloat
 DataType_Name of x_13: kFloat
 DataType_Name of x_14: kFloat
 DataType_Name of x_15: kFloat
 DataType_Name of x_16: kFloat
 DataType_Name of x_17: kFloat
 DataType_Name of x_18: kFloat
 DataType_Name of x_19: kFloat
 DataType_Name of x_20: kFloat
 DataType_Name of x_21: kFloat
 DataType_Name of x_22: kFloat
 DataType_Name of x_23: kFloat
 DataType_Name of x_24: kFloat
 DataType_Name of x_25: kFloat
 DataType_Name of x_26: kFloat
 DataType_Name of x_27: kFloat
 DataType_Name of x_28: kFloat
 DataType_Name of x_29: kFloat
 DataType_Name of x_30: kFloat
 DataType_Name of x_31: kFloat
 DataType_Name of x_32: kFloat
 DataType_Name of x_33: kFloat
 DataType_Name of x_34: kFloat
 DataType_Name of x_35: kFloat
 DataType_Name of x_36: kFloat
 DataType_Name of x_37: kFloat
 DataType_Name of x_38: kFloat
 DataType_Name of x_39: kFloat
 DataType_Name of x_40: kFloat
 DataType_Name of x_41: kFloat
 DataType_Name of x_42: kFloat
 DataType_Name of x_43: kFloat
 DataType_Name of x_44: kFloat
 DataType_Name of x_45: kFloat
 DataType_Name of x_46: kFloat
 DataType_Name of x_47: kFloat
 DataType_Name of x_48: kFloat
 DataType_Name of x_49: kFloat
 DataType_Name of x_50: kFloat
 DataType_Name of x_51: kFloat
 DataType_Name of x_52: kFloat
 DataType_Name of x_53: kFloat
 DataType_Name of x_54: kFloat
 DataType_Name of x_55: kFloat
 DataType_Name of x_56: kFloat
 DataType_Name of x_57: kFloat
 DataType_Name of x_58: kFloat
 DataType_Name of x_59: kFloat
 DataType_Name of x_60: kFloat
 DataType_Name of x_61: kFloat
 DataType_Name of x_62: kFloat
 DataType_Name of x_63: kFloat
 DataType_Name of x_64: kFloat
 DataType_Name of x_65: kFloat
 DataType_Name of x_66: kFloat
 DataType_Name of x_67: kFloat
 DataType_Name of x_68: kFloat
 DataType_Name of x_69: kFloat
 DataType_Name of x_70: kFloat
 DataType_Name of x_71: kFloat
 DataType_Name of x_72: kFloat
 DataType_Name of x_73: kFloat
 DataType_Name of x_74: kFloat
 DataType_Name of x_75: kFloat
 DataType_Name of x_76: kFloat
 DataType_Name of x_77: kFloat
 DataType_Name of x_78: kFloat
 DataType_Name of x_79: kFloat
 DataType_Name of x_80: kFloat
 DataType_Name of x_81: kFloat
 DataType_Name of x_82: kFloat
 DataType_Name of x_83: kFloat
 DataType_Name of x_84: kFloat
 DataType_Name of x_85: kFloat
 DataType_Name of x_86: kFloat
 DataType_Name of x_87: kFloat
 DataType_Name of x_88: kFloat
 DataType_Name of x_89: kFloat
 DataType_Name of x_90: kFloat
 DataType_Name of x_91: kFloat
 DataType_Name of x_92: kFloat
 DataType_Name of x_93: kFloat
 DataType_Name of x_94: kFloat
 DataType_Name of x_95: kFloat
 DataType_Name of x_96: kFloat
 DataType_Name of x_97: kFloat
 DataType_Name of y_0: kFloat
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name 

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 16:17:54] lb.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[03/28 16:26:02] libai INFO: Rank of current process: 0. World size: 1
[03/28 16:26:02] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 16:26:03] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 16:26:03] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 16:26:03] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 16:26:03] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.309 seconds
[03/28 16:26:03] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.310 seconds
[03/28 16:26:06] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.011565 seconds
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 16:26:06] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.007 seconds
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:26:06] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:26:06] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 16:26:06] libai INFO: > Start building model...
[03/28 16:26:07] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 16:26:07] libai INFO: >>> done with building model. Building time: 0.790 seconds
[03/28 16:26:07] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 16:26:09] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 16:26:09] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 16:26:17] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: System-DynamicLossScale-MultiCountNotFinite-366
 op_type_name: multi_count_not_finite
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of x_1: kFloat
 DataType_Name of x_2: kFloat
 DataType_Name of x_3: kFloat
 DataType_Name of x_4: kFloat
 DataType_Name of x_5: kFloat
 DataType_Name of x_6: kFloat
 DataType_Name of x_7: kFloat
 DataType_Name of x_8: kFloat
 DataType_Name of x_9: kFloat
 DataType_Name of x_10: kFloat
 DataType_Name of x_11: kFloat
 DataType_Name of x_12: kFloat
 DataType_Name of x_13: kFloat
 DataType_Name of x_14: kFloat
 DataType_Name of x_15: kFloat
 DataType_Name of x_16: kFloat
 DataType_Name of x_17: kFloat
 DataType_Name of x_18: kFloat
 DataType_Name of x_19: kFloat
 DataType_Name of x_20: kFloat
 DataType_Name of x_21: kFloat
 DataType_Name of x_22: kFloat
 DataType_Name of x_23: kFloat
 DataType_Name of x_24: kFloat
 DataType_Name of x_25: kFloat
 DataType_Name of x_26: kFloat
 DataType_Name of x_27: kFloat
 DataType_Name of x_28: kFloat
 DataType_Name of x_29: kFloat
 DataType_Name of x_30: kFloat
 DataType_Name of x_31: kFloat
 DataType_Name of x_32: kFloat
 DataType_Name of x_33: kFloat
 DataType_Name of x_34: kFloat
 DataType_Name of x_35: kFloat
 DataType_Name of x_36: kFloat
 DataType_Name of x_37: kFloat
 DataType_Name of x_38: kFloat
 DataType_Name of x_39: kFloat
 DataType_Name of x_40: kFloat
 DataType_Name of x_41: kFloat
 DataType_Name of x_42: kFloat
 DataType_Name of x_43: kFloat
 DataType_Name of x_44: kFloat
 DataType_Name of x_45: kFloat
 DataType_Name of x_46: kFloat
 DataType_Name of x_47: kFloat
 DataType_Name of x_48: kFloat
 DataType_Name of x_49: kFloat
 DataType_Name of x_50: kFloat
 DataType_Name of x_51: kFloat
 DataType_Name of x_52: kFloat
 DataType_Name of x_53: kFloat
 DataType_Name of x_54: kFloat
 DataType_Name of x_55: kFloat
 DataType_Name of x_56: kFloat
 DataType_Name of x_57: kFloat
 DataType_Name of x_58: kFloat
 DataType_Name of x_59: kFloat
 DataType_Name of x_60: kFloat
 DataType_Name of x_61: kFloat
 DataType_Name of x_62: kFloat
 DataType_Name of x_63: kFloat
 DataType_Name of x_64: kFloat
 DataType_Name of x_65: kFloat
 DataType_Name of x_66: kFloat
 DataType_Name of x_67: kFloat
 DataType_Name of x_68: kFloat
 DataType_Name of x_69: kFloat
 DataType_Name of x_70: kFloat
 DataType_Name of x_71: kFloat
 DataType_Name of x_72: kFloat
 DataType_Name of x_73: kFloat
 DataType_Name of x_74: kFloat
 DataType_Name of x_75: kFloat
 DataType_Name of x_76: kFloat
 DataType_Name of x_77: kFloat
 DataType_Name of x_78: kFloat
 DataType_Name of x_79: kFloat
 DataType_Name of x_80: kFloat
 DataType_Name of x_81: kFloat
 DataType_Name of x_82: kFloat
 DataType_Name of x_83: kFloat
 DataType_Name of x_84: kFloat
 DataType_Name of x_85: kFloat
 DataType_Name of x_86: kFloat
 DataType_Name of x_87: kFloat
 DataType_Name of x_88: kFloat
 DataType_Name of x_89: kFloat
 DataType_Name of x_90: kFloat
 DataType_Name of x_91: kFloat
 DataType_Name of x_92: kFloat
 DataType_Name of x_93: kFloat
 DataType_Name of x_94: kFloat
 DataType_Name of x_95: kFloat
 DataType_Name of x_96: kFloat
 DataType_Name of x_97: kFloat
 DataType_Name of x_98: kFloat
 DataType_Name of x_99: kFloat
 DataType_Name of x_100: kFloat
 DataType_Name of x_101: kFloat
 DataType_Name of x_102: kFloat
 DataType_Name of x_103: kFloat
 DataType_Name of x_104: kFloat
 DataType_Name of x_105: kFloat
 DataType_Name of x_106: kFloat
 DataType_Name of x_107: kFloat
 DataType_Name of x_108: kFloat
 DataType_Name of x_109: kFloat
 DataType_Name of x_110: kFloat
 DataType_Name of x_111: kFloat
 DataType_Name of x_112: kFloat
 DataType_Name of x_113: kFloat
 DataType_Name of x_114: kFloat
 DataType_Name of x_115: kFloat
 DataType_Name of x_116: kFloat
 DataType_Name of x_117: kFloat
 DataType_Name of x_118: kFloat
 DataType_Name of x_119: kFloat
 DataType_Name of x_120: kFloat
 DataType_Name of x_121: kFloat
 DataType_Name of x_122: kFloat
 DataType_Name of x_123: kFloat
 DataType_Name of x_124: kFloat
 DataType_Name of x_125: kFloat
 DataType_Name of x_126: kFloat
 DataType_Name of x_127: kFloat
 DataType_Name of x_128: kFloat
 DataType_Name of x_129: kFloat
 DataType_Name of x_130: kFloat
 DataType_Name of x_131: kFloat
 DataType_Name of x_132: kFloat
 DataType_Name of x_133: kFloat
 DataType_Name of x_134: kFloat
 DataType_Name of x_135: kFloat
 DataType_Name of x_136: kFloat
 DataType_Name of x_137: kFloat
 DataType_Name of x_138: kFloat
 DataType_Name of x_139: kFloat
 DataType_Name of x_140: kFloat
 DataType_Name of x_141: kFloat
 DataType_Name of x_142: kFloat
 DataType_Name of x_143: kFloat
 DataType_Name of x_144: kFloat
 DataType_Name of x_145: kFloat
 DataType_Name of x_146: kFloat
 DataType_Name of x_147: kFloat
 DataType_Name of y_0: kInt64
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name 

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 16:26:17] lb.engine.hooks INFO: Total training time: 0:00:08 (0:00:00 on hooks)
[03/28 16:29:20] libai INFO: Rank of current process: 0. World size: 1
[03/28 16:29:20] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 16:29:20] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 16:29:20] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 16:29:20] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 16:29:20] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.187 seconds
[03/28 16:29:20] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.187 seconds
[03/28 16:29:24] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.011708 seconds
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 16:29:24] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.009 seconds
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.002 seconds
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:29:24] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:29:24] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 16:29:24] libai INFO: > Start building model...
[03/28 16:29:25] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 16:29:25] libai INFO: >>> done with building model. Building time: 0.518 seconds
[03/28 16:29:25] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 16:29:27] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 16:29:27] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 16:29:37] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: System-DynamicLossScale-MultiCountNotFinite-366
 op_type_name: multi_count_not_finite
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of x_1: kFloat
 DataType_Name of x_2: kFloat
 DataType_Name of x_3: kFloat
 DataType_Name of x_4: kFloat
 DataType_Name of x_5: kFloat
 DataType_Name of x_6: kFloat
 DataType_Name of x_7: kFloat
 DataType_Name of x_8: kFloat
 DataType_Name of x_9: kFloat
 DataType_Name of x_10: kFloat
 DataType_Name of x_11: kFloat
 DataType_Name of x_12: kFloat
 DataType_Name of x_13: kFloat
 DataType_Name of x_14: kFloat
 DataType_Name of x_15: kFloat
 DataType_Name of x_16: kFloat
 DataType_Name of x_17: kFloat
 DataType_Name of x_18: kFloat
 DataType_Name of x_19: kFloat
 DataType_Name of x_20: kFloat
 DataType_Name of x_21: kFloat
 DataType_Name of x_22: kFloat
 DataType_Name of x_23: kFloat
 DataType_Name of x_24: kFloat
 DataType_Name of x_25: kFloat
 DataType_Name of x_26: kFloat
 DataType_Name of x_27: kFloat
 DataType_Name of x_28: kFloat
 DataType_Name of x_29: kFloat
 DataType_Name of x_30: kFloat
 DataType_Name of x_31: kFloat
 DataType_Name of x_32: kFloat
 DataType_Name of x_33: kFloat
 DataType_Name of x_34: kFloat
 DataType_Name of x_35: kFloat
 DataType_Name of x_36: kFloat
 DataType_Name of x_37: kFloat
 DataType_Name of x_38: kFloat
 DataType_Name of x_39: kFloat
 DataType_Name of x_40: kFloat
 DataType_Name of x_41: kFloat
 DataType_Name of x_42: kFloat
 DataType_Name of x_43: kFloat
 DataType_Name of x_44: kFloat
 DataType_Name of x_45: kFloat
 DataType_Name of x_46: kFloat
 DataType_Name of x_47: kFloat
 DataType_Name of x_48: kFloat
 DataType_Name of x_49: kFloat
 DataType_Name of x_50: kFloat
 DataType_Name of x_51: kFloat
 DataType_Name of x_52: kFloat
 DataType_Name of x_53: kFloat
 DataType_Name of x_54: kFloat
 DataType_Name of x_55: kFloat
 DataType_Name of x_56: kFloat
 DataType_Name of x_57: kFloat
 DataType_Name of x_58: kFloat
 DataType_Name of x_59: kFloat
 DataType_Name of x_60: kFloat
 DataType_Name of x_61: kFloat
 DataType_Name of x_62: kFloat
 DataType_Name of x_63: kFloat
 DataType_Name of x_64: kFloat
 DataType_Name of x_65: kFloat
 DataType_Name of x_66: kFloat
 DataType_Name of x_67: kFloat
 DataType_Name of x_68: kFloat
 DataType_Name of x_69: kFloat
 DataType_Name of x_70: kFloat
 DataType_Name of x_71: kFloat
 DataType_Name of x_72: kFloat
 DataType_Name of x_73: kFloat
 DataType_Name of x_74: kFloat
 DataType_Name of x_75: kFloat
 DataType_Name of x_76: kFloat
 DataType_Name of x_77: kFloat
 DataType_Name of x_78: kFloat
 DataType_Name of x_79: kFloat
 DataType_Name of x_80: kFloat
 DataType_Name of x_81: kFloat
 DataType_Name of x_82: kFloat
 DataType_Name of x_83: kFloat
 DataType_Name of x_84: kFloat
 DataType_Name of x_85: kFloat
 DataType_Name of x_86: kFloat
 DataType_Name of x_87: kFloat
 DataType_Name of x_88: kFloat
 DataType_Name of x_89: kFloat
 DataType_Name of x_90: kFloat
 DataType_Name of x_91: kFloat
 DataType_Name of x_92: kFloat
 DataType_Name of x_93: kFloat
 DataType_Name of x_94: kFloat
 DataType_Name of x_95: kFloat
 DataType_Name of x_96: kFloat
 DataType_Name of x_97: kFloat
 DataType_Name of x_98: kFloat
 DataType_Name of x_99: kFloat
 DataType_Name of x_100: kFloat
 DataType_Name of x_101: kFloat
 DataType_Name of x_102: kFloat
 DataType_Name of x_103: kFloat
 DataType_Name of x_104: kFloat
 DataType_Name of x_105: kFloat
 DataType_Name of x_106: kFloat
 DataType_Name of x_107: kFloat
 DataType_Name of x_108: kFloat
 DataType_Name of x_109: kFloat
 DataType_Name of x_110: kFloat
 DataType_Name of x_111: kFloat
 DataType_Name of x_112: kFloat
 DataType_Name of x_113: kFloat
 DataType_Name of x_114: kFloat
 DataType_Name of x_115: kFloat
 DataType_Name of x_116: kFloat
 DataType_Name of x_117: kFloat
 DataType_Name of x_118: kFloat
 DataType_Name of x_119: kFloat
 DataType_Name of x_120: kFloat
 DataType_Name of x_121: kFloat
 DataType_Name of x_122: kFloat
 DataType_Name of x_123: kFloat
 DataType_Name of x_124: kFloat
 DataType_Name of x_125: kFloat
 DataType_Name of x_126: kFloat
 DataType_Name of x_127: kFloat
 DataType_Name of x_128: kFloat
 DataType_Name of x_129: kFloat
 DataType_Name of x_130: kFloat
 DataType_Name of x_131: kFloat
 DataType_Name of x_132: kFloat
 DataType_Name of x_133: kFloat
 DataType_Name of x_134: kFloat
 DataType_Name of x_135: kFloat
 DataType_Name of x_136: kFloat
 DataType_Name of x_137: kFloat
 DataType_Name of x_138: kFloat
 DataType_Name of x_139: kFloat
 DataType_Name of x_140: kFloat
 DataType_Name of x_141: kFloat
 DataType_Name of x_142: kFloat
 DataType_Name of x_143: kFloat
 DataType_Name of x_144: kFloat
 DataType_Name of x_145: kFloat
 DataType_Name of x_146: kFloat
 DataType_Name of x_147: kFloat
 DataType_Name of y_0: kInt64
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name 

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 16:29:37] lb.engine.hooks INFO: Total training time: 0:00:10 (0:00:00 on hooks)
[03/28 16:58:19] libai INFO: Rank of current process: 0. World size: 1
[03/28 16:58:19] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 16:58:19] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 16:58:19] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 16:58:19] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 16:58:19] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.056 seconds
[03/28 16:58:19] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.056 seconds
[03/28 16:58:22] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008211 seconds
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 16:58:22] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.005 seconds
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 16:58:22] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 16:58:22] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 16:58:22] libai INFO: > Start building model...
[03/28 16:58:23] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 16:58:23] libai INFO: >>> done with building model. Building time: 0.891 seconds
[03/28 16:58:23] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 16:58:25] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 16:58:25] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 16:58:31] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: System-DynamicLossScale-MultiCountNotFinite-366
 op_type_name: multi_count_not_finite
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of x_1: kFloat
 DataType_Name of x_2: kFloat
 DataType_Name of x_3: kFloat
 DataType_Name of x_4: kFloat
 DataType_Name of x_5: kFloat
 DataType_Name of x_6: kFloat
 DataType_Name of x_7: kFloat
 DataType_Name of x_8: kFloat
 DataType_Name of x_9: kFloat
 DataType_Name of x_10: kFloat
 DataType_Name of x_11: kFloat
 DataType_Name of x_12: kFloat
 DataType_Name of x_13: kFloat
 DataType_Name of x_14: kFloat
 DataType_Name of x_15: kFloat
 DataType_Name of x_16: kFloat
 DataType_Name of x_17: kFloat
 DataType_Name of x_18: kFloat
 DataType_Name of x_19: kFloat
 DataType_Name of x_20: kFloat
 DataType_Name of x_21: kFloat
 DataType_Name of x_22: kFloat
 DataType_Name of x_23: kFloat
 DataType_Name of x_24: kFloat
 DataType_Name of x_25: kFloat
 DataType_Name of x_26: kFloat
 DataType_Name of x_27: kFloat
 DataType_Name of x_28: kFloat
 DataType_Name of x_29: kFloat
 DataType_Name of x_30: kFloat
 DataType_Name of x_31: kFloat
 DataType_Name of x_32: kFloat
 DataType_Name of x_33: kFloat
 DataType_Name of x_34: kFloat
 DataType_Name of x_35: kFloat
 DataType_Name of x_36: kFloat
 DataType_Name of x_37: kFloat
 DataType_Name of x_38: kFloat
 DataType_Name of x_39: kFloat
 DataType_Name of x_40: kFloat
 DataType_Name of x_41: kFloat
 DataType_Name of x_42: kFloat
 DataType_Name of x_43: kFloat
 DataType_Name of x_44: kFloat
 DataType_Name of x_45: kFloat
 DataType_Name of x_46: kFloat
 DataType_Name of x_47: kFloat
 DataType_Name of x_48: kFloat
 DataType_Name of x_49: kFloat
 DataType_Name of x_50: kFloat
 DataType_Name of x_51: kFloat
 DataType_Name of x_52: kFloat
 DataType_Name of x_53: kFloat
 DataType_Name of x_54: kFloat
 DataType_Name of x_55: kFloat
 DataType_Name of x_56: kFloat
 DataType_Name of x_57: kFloat
 DataType_Name of x_58: kFloat
 DataType_Name of x_59: kFloat
 DataType_Name of x_60: kFloat
 DataType_Name of x_61: kFloat
 DataType_Name of x_62: kFloat
 DataType_Name of x_63: kFloat
 DataType_Name of x_64: kFloat
 DataType_Name of x_65: kFloat
 DataType_Name of x_66: kFloat
 DataType_Name of x_67: kFloat
 DataType_Name of x_68: kFloat
 DataType_Name of x_69: kFloat
 DataType_Name of x_70: kFloat
 DataType_Name of x_71: kFloat
 DataType_Name of x_72: kFloat
 DataType_Name of x_73: kFloat
 DataType_Name of x_74: kFloat
 DataType_Name of x_75: kFloat
 DataType_Name of x_76: kFloat
 DataType_Name of x_77: kFloat
 DataType_Name of x_78: kFloat
 DataType_Name of x_79: kFloat
 DataType_Name of x_80: kFloat
 DataType_Name of x_81: kFloat
 DataType_Name of x_82: kFloat
 DataType_Name of x_83: kFloat
 DataType_Name of x_84: kFloat
 DataType_Name of x_85: kFloat
 DataType_Name of x_86: kFloat
 DataType_Name of x_87: kFloat
 DataType_Name of x_88: kFloat
 DataType_Name of x_89: kFloat
 DataType_Name of x_90: kFloat
 DataType_Name of x_91: kFloat
 DataType_Name of x_92: kFloat
 DataType_Name of x_93: kFloat
 DataType_Name of x_94: kFloat
 DataType_Name of x_95: kFloat
 DataType_Name of x_96: kFloat
 DataType_Name of x_97: kFloat
 DataType_Name of x_98: kFloat
 DataType_Name of x_99: kFloat
 DataType_Name of x_100: kFloat
 DataType_Name of x_101: kFloat
 DataType_Name of x_102: kFloat
 DataType_Name of x_103: kFloat
 DataType_Name of x_104: kFloat
 DataType_Name of x_105: kFloat
 DataType_Name of x_106: kFloat
 DataType_Name of x_107: kFloat
 DataType_Name of x_108: kFloat
 DataType_Name of x_109: kFloat
 DataType_Name of x_110: kFloat
 DataType_Name of x_111: kFloat
 DataType_Name of x_112: kFloat
 DataType_Name of x_113: kFloat
 DataType_Name of x_114: kFloat
 DataType_Name of x_115: kFloat
 DataType_Name of x_116: kFloat
 DataType_Name of x_117: kFloat
 DataType_Name of x_118: kFloat
 DataType_Name of x_119: kFloat
 DataType_Name of x_120: kFloat
 DataType_Name of x_121: kFloat
 DataType_Name of x_122: kFloat
 DataType_Name of x_123: kFloat
 DataType_Name of x_124: kFloat
 DataType_Name of x_125: kFloat
 DataType_Name of x_126: kFloat
 DataType_Name of x_127: kFloat
 DataType_Name of x_128: kFloat
 DataType_Name of x_129: kFloat
 DataType_Name of x_130: kFloat
 DataType_Name of x_131: kFloat
 DataType_Name of x_132: kFloat
 DataType_Name of x_133: kFloat
 DataType_Name of x_134: kFloat
 DataType_Name of x_135: kFloat
 DataType_Name of x_136: kFloat
 DataType_Name of x_137: kFloat
 DataType_Name of x_138: kFloat
 DataType_Name of x_139: kFloat
 DataType_Name of x_140: kFloat
 DataType_Name of x_141: kFloat
 DataType_Name of x_142: kFloat
 DataType_Name of x_143: kFloat
 DataType_Name of x_144: kFloat
 DataType_Name of x_145: kFloat
 DataType_Name of x_146: kFloat
 DataType_Name of x_147: kFloat
 DataType_Name of y_0: kInt64
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name 

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 16:58:31] lb.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[03/28 17:05:44] libai INFO: Rank of current process: 0. World size: 1
[03/28 17:05:44] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[03/28 17:05:44] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m


[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_max_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mclip_grad_norm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m50[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=2 * model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[03/28 17:05:44] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[03/28 17:05:44] lb.engine.default INFO: > compiling dataset index builder ...
[03/28 17:05:44] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.043 seconds
[03/28 17:05:44] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.044 seconds
[03/28 17:05:46] lb.engine.default INFO: Prepare training, validating, testing set
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: reading document index...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007315 seconds
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[03/28 17:05:46] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[03/28 17:05:46] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[03/28 17:05:47] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[03/28 17:05:47] libai INFO: > Start building model...
[03/28 17:05:47] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[03/28 17:05:47] libai INFO: >>> done with building model. Building time: 0.294 seconds
[03/28 17:05:47] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[03/28 17:05:48] lb.engine.trainer INFO: Starting training from iteration 0
[03/28 17:05:48] lb.models.utils.graph_base INFO: Start compiling the train graph which may take some time. Please wait for a moment ...
[03/28 17:05:54] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 339, in run_step
    loss_dict = self.graph(**data)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 243, in __call__
    self._compile(*args, **kwargs)
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 809, in _compile
    self.finish_compile_and_init_runtime()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/graph/graph.py", line 1165, in finish_compile_and_init_runtime
    self._c_nn_graph.compile_plan_for_runtime()
oneflow._oneflow_internal.exception.RuntimeError: [1m[38;2;255;000;000mError[0m: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: System-DynamicLossScale-MultiCountNotFinite-366
 op_type_name: multi_count_not_finite
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of x_1: kFloat
 DataType_Name of x_2: kFloat
 DataType_Name of x_3: kFloat
 DataType_Name of x_4: kFloat
 DataType_Name of x_5: kFloat
 DataType_Name of x_6: kFloat
 DataType_Name of x_7: kFloat
 DataType_Name of x_8: kFloat
 DataType_Name of x_9: kFloat
 DataType_Name of x_10: kFloat
 DataType_Name of x_11: kFloat
 DataType_Name of x_12: kFloat
 DataType_Name of x_13: kFloat
 DataType_Name of x_14: kFloat
 DataType_Name of x_15: kFloat
 DataType_Name of x_16: kFloat
 DataType_Name of x_17: kFloat
 DataType_Name of x_18: kFloat
 DataType_Name of x_19: kFloat
 DataType_Name of x_20: kFloat
 DataType_Name of x_21: kFloat
 DataType_Name of x_22: kFloat
 DataType_Name of x_23: kFloat
 DataType_Name of x_24: kFloat
 DataType_Name of x_25: kFloat
 DataType_Name of x_26: kFloat
 DataType_Name of x_27: kFloat
 DataType_Name of x_28: kFloat
 DataType_Name of x_29: kFloat
 DataType_Name of x_30: kFloat
 DataType_Name of x_31: kFloat
 DataType_Name of x_32: kFloat
 DataType_Name of x_33: kFloat
 DataType_Name of x_34: kFloat
 DataType_Name of x_35: kFloat
 DataType_Name of x_36: kFloat
 DataType_Name of x_37: kFloat
 DataType_Name of x_38: kFloat
 DataType_Name of x_39: kFloat
 DataType_Name of x_40: kFloat
 DataType_Name of x_41: kFloat
 DataType_Name of x_42: kFloat
 DataType_Name of x_43: kFloat
 DataType_Name of x_44: kFloat
 DataType_Name of x_45: kFloat
 DataType_Name of x_46: kFloat
 DataType_Name of x_47: kFloat
 DataType_Name of x_48: kFloat
 DataType_Name of x_49: kFloat
 DataType_Name of x_50: kFloat
 DataType_Name of x_51: kFloat
 DataType_Name of x_52: kFloat
 DataType_Name of x_53: kFloat
 DataType_Name of x_54: kFloat
 DataType_Name of x_55: kFloat
 DataType_Name of x_56: kFloat
 DataType_Name of x_57: kFloat
 DataType_Name of x_58: kFloat
 DataType_Name of x_59: kFloat
 DataType_Name of x_60: kFloat
 DataType_Name of x_61: kFloat
 DataType_Name of x_62: kFloat
 DataType_Name of x_63: kFloat
 DataType_Name of x_64: kFloat
 DataType_Name of x_65: kFloat
 DataType_Name of x_66: kFloat
 DataType_Name of x_67: kFloat
 DataType_Name of x_68: kFloat
 DataType_Name of x_69: kFloat
 DataType_Name of x_70: kFloat
 DataType_Name of x_71: kFloat
 DataType_Name of x_72: kFloat
 DataType_Name of x_73: kFloat
 DataType_Name of x_74: kFloat
 DataType_Name of x_75: kFloat
 DataType_Name of x_76: kFloat
 DataType_Name of x_77: kFloat
 DataType_Name of x_78: kFloat
 DataType_Name of x_79: kFloat
 DataType_Name of x_80: kFloat
 DataType_Name of x_81: kFloat
 DataType_Name of x_82: kFloat
 DataType_Name of x_83: kFloat
 DataType_Name of x_84: kFloat
 DataType_Name of x_85: kFloat
 DataType_Name of x_86: kFloat
 DataType_Name of x_87: kFloat
 DataType_Name of x_88: kFloat
 DataType_Name of x_89: kFloat
 DataType_Name of x_90: kFloat
 DataType_Name of x_91: kFloat
 DataType_Name of x_92: kFloat
 DataType_Name of x_93: kFloat
 DataType_Name of x_94: kFloat
 DataType_Name of x_95: kFloat
 DataType_Name of x_96: kFloat
 DataType_Name of x_97: kFloat
 DataType_Name of x_98: kFloat
 DataType_Name of x_99: kFloat
 DataType_Name of x_100: kFloat
 DataType_Name of x_101: kFloat
 DataType_Name of x_102: kFloat
 DataType_Name of x_103: kFloat
 DataType_Name of x_104: kFloat
 DataType_Name of x_105: kFloat
 DataType_Name of x_106: kFloat
 DataType_Name of x_107: kFloat
 DataType_Name of x_108: kFloat
 DataType_Name of x_109: kFloat
 DataType_Name of x_110: kFloat
 DataType_Name of x_111: kFloat
 DataType_Name of x_112: kFloat
 DataType_Name of x_113: kFloat
 DataType_Name of x_114: kFloat
 DataType_Name of x_115: kFloat
 DataType_Name of x_116: kFloat
 DataType_Name of x_117: kFloat
 DataType_Name of x_118: kFloat
 DataType_Name of x_119: kFloat
 DataType_Name of x_120: kFloat
 DataType_Name of x_121: kFloat
 DataType_Name of x_122: kFloat
 DataType_Name of x_123: kFloat
 DataType_Name of x_124: kFloat
 DataType_Name of x_125: kFloat
 DataType_Name of x_126: kFloat
 DataType_Name of x_127: kFloat
 DataType_Name of x_128: kFloat
 DataType_Name of x_129: kFloat
 DataType_Name of x_130: kFloat
 DataType_Name of x_131: kFloat
 DataType_Name of x_132: kFloat
 DataType_Name of x_133: kFloat
 DataType_Name of x_134: kFloat
 DataType_Name of x_135: kFloat
 DataType_Name of x_136: kFloat
 DataType_Name of x_137: kFloat
 DataType_Name of x_138: kFloat
 DataType_Name of x_139: kFloat
 DataType_Name of x_140: kFloat
 DataType_Name of x_141: kFloat
 DataType_Name of x_142: kFloat
 DataType_Name of x_143: kFloat
 DataType_Name of x_144: kFloat
 DataType_Name of x_145: kFloat
 DataType_Name of x_146: kFloat
 DataType_Name of x_147: kFloat
 DataType_Name of y_0: kInt64
Error message from /home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp:120
	op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc()):  infer blob descs if failed, op name 

  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in InferBlobDescs
    op_->InferBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, &GlobalJobDesc())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/operator.cpp", line 351, in InferBlobDescsIf
    InferInternalBlobDescsIf(GetBlobDesc4BnInOp, parallel_ctx, job_desc)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/operator/user_op.cpp", line 711, in InferInternalBlobDescs
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult( op_conf().user_conf().op_type_name(), UserOpKernelRegContext(this, GetBlobDesc4BnInOp, parallel_ctx))
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/graph/exec_graph.cpp", line 120, in operator()
    
Error Type: oneflow.ErrorProto.runtime_error

[03/28 17:05:54] lb.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
