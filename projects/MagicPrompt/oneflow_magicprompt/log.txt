[04/17 16:45:18] libai INFO: Rank of current process: 0. World size: 1
[04/17 16:45:18] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[04/17 16:45:18] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[04/17 16:45:18] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[04/17 16:45:18] lb.engine.default INFO: > compiling dataset index builder ...
[04/17 16:45:18] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.045 seconds
[04/17 16:45:18] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.046 seconds
[04/17 16:45:20] lb.engine.default INFO: Prepare training, validating, testing set
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: reading document index...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.008423 seconds
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[04/17 16:45:20] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[04/17 16:45:20] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[04/17 16:45:20] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[04/17 16:45:20] libai INFO: > Start building model...
[04/17 16:45:20] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[04/17 16:45:20] libai INFO: >>> done with building model. Building time: 0.182 seconds
[04/17 16:45:20] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[04/17 16:45:20] lb.engine.trainer INFO: Starting training from iteration 0
[04/17 16:45:21] lb.engine.trainer ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 146, in train
    self.run_step()
  File "/home/zhangxiaoyu/libai/libai/engine/default.py", line 491, in run_step
    self._trainer.run_step(self.get_batch, self.cfg.train.input_placement_device)
  File "/home/zhangxiaoyu/libai/libai/engine/trainer.py", line 284, in run_step
    self.optimizer.clip_grad()
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/optim/optimizer.py", line 508, in clip_grad
    clip_grad_norm_(
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/utils/clip_grad.py", line 123, in clip_grad_norm_
    [
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/nn/utils/clip_grad.py", line 124, in <listcomp>
    flow.linalg.vector_norm(
  File "/home/zhangxiaoyu/oneflow-cambricon/python/oneflow/linalg.py", line 24, in vector_norm
    return flow._C.vector_norm(self, ord, dim, keepdim, dtype=dtype)
RuntimeError: Cannot find the kernel matching Current OperatorConf.  The Info of OperatorConf are 
 op_name: sqrt_square_sum66
 op_type_name: sqrt_square_sum
 DeviceType_Name: kMLU
 DataType_Name of x_0: kFloat
 DataType_Name of y_0: kFloat
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/functional/impl/math_functor.cpp", line 1579, in operator()
    SqrtSquareSum(x)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp", line 144, in Dispatch<oneflow::one::Tensor>
    Dispatch<TensorTuple>(op_expr, inputs, ctx)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp", line 135, in Dispatch<oneflow::one::TensorTuple>
    Dispatch(op_expr, inputs, outputs.get(), ctx)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/op_interpreter/op_interpreter.cpp", line 96, in Apply
    internal_->Apply(op_expr, inputs, outputs, ctx)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/op_interpreter/eager_global_op_interpreter.cpp", line 176, in Interpret
    PhysicalRun([&](InstructionsBuilder* builder) -> Maybe ... output_eager_blob_objects), result, ctx, result->stream()); })
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/instructions_builder.h", line 167, in PhysicalRun
    Build(&instructions_builder)
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/framework/instructions_builder.cpp", line 401, in Call
    vm::OpCallInstructionPolicy::New( vm_stream, opkernel ... global_tensor_infer_result, ctx, *one::CurrentDevVmDepObjectConsumeMode())
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/core/vm/op_call_instruction_policy.h", line 47, in New
    ptr->Init()
  File "/home/zhangxiaoyu/oneflow-cambricon/oneflow/user/kernels/stateful_opkernel.cpp", line 918, in ChooseOpKernel
    user_op::UserOpRegistryMgr::Get().GetOpKernelRegistryResult(op_type_name, reg_ctx)
Error Type: oneflow.ErrorProto.op_kernel_not_found_error
[04/17 16:45:21] lb.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[04/17 16:45:48] libai INFO: Rank of current process: 0. World size: 1
[04/17 16:45:48] libai INFO: Command line arguments: Namespace(config_file='projects/MagicPrompt/configs/gpt2_training.py', eval_only=False, fast_dev_run=False, opts=[], resume=False)
[04/17 16:45:48] libai INFO: Contents of args.config_file=projects/MagicPrompt/configs/gpt2_training.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mLazyCall[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mevaluation[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mPPLEvaluator[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_inference[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mpretrain_model[39m[38;5;15m [39m[38;5;81mas[39m[38;5;15m [39m[38;5;15mmodel[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mprojects[39m[38;5;15m.[39m[38;5;15mMagicPrompt[39m[38;5;15m.[39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mgpt2_dataset[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mtokenization[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15moptim[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15moptim[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mlibai[39m[38;5;15m.[39m[38;5;15mscheduler[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mWarmupExponentialLR[39m

[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mtrain[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mtrain[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mconfigs[39m[38;5;15m.[39m[38;5;15mcommon[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mgraph[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mgraph[39m

[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mFalse[39m
[38;5;15mgraph[39m[38;5;197m.[39m[38;5;15mdebug[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/vocab.json[39m[38;5;186m"[39m
[38;5;15mmerge_files[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/merges.txt[39m[38;5;186m"[39m
[38;5;15mtrain_data_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m/home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence[39m[38;5;186m"[39m

[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mvocab_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mvocab_file[39m
[38;5;15mtokenization[39m[38;5;197m.[39m[38;5;15mtokenizer[39m[38;5;197m.[39m[38;5;15mmerges_file[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmerge_files[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m[[39m[38;5;141m0[39m[38;5;15m][39m[38;5;197m.[39m[38;5;15mindexed_dataset[39m[38;5;197m.[39m[38;5;15mdata_prefix[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain_data_prefix[39m

[38;5;242m# gpt2 model config[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mpretrained_model_path[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mNone[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15membedding_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mattention_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15moutput_dropout_prob[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mnum_attention_heads[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mffn_hidden_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m4[39m[38;5;15m [39m[38;5;197m*[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15minitializer_range[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mvocab_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m50257[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mlayernorm_epsilon[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-5[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15muse_scaled_init_for_output_weights[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_gelu_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mbias_dropout_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mscale_mask_softmax_fusion[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_query_key_layer_scaling[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mapply_residual_post_layernorm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mFalse[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mamp_enabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minput_placement_device[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcpu[39m[38;5;186m"[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdist[39m[38;5;197m.[39m[38;5;15mpipeline_num_layers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mhidden_layers[39m

[38;5;81mfor[39m[38;5;15m [39m[38;5;15mds[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdataset[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15mds[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mcfg[39m[38;5;197m.[39m[38;5;15mmax_seq_length[39m

[38;5;15moptim[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5.0e-05[39m

[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mupdate[39m[38;5;15m([39m
[38;5;15m    [39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m        [39m[38;5;15moutput_dir[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mprojects/MagicPrompt/oneflow_magicprompt[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtest_micro_batch_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_epoch[39m[38;5;197m=[39m[38;5;141m33[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mtrain_iter[39m[38;5;197m=[39m[38;5;141m10000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mlog_period[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mamp[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mwarmup_ratio[39m[38;5;197m=[39m[38;5;141m0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mcheckpointer[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m[38;5;15mperiod[39m[38;5;197m=[39m[38;5;141m8000[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15mmax_to_keep[39m[38;5;197m=[39m[38;5;141m20[39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mdist[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mdata_parallel_size[39m[38;5;197m=[39m[38;5;141m4[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mtensor_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mpipeline_parallel_size[39m[38;5;197m=[39m[38;5;141m1[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers = 12,[39m
[38;5;15m            [39m[38;5;242m# custom_pipeline_stage_id = [0] * 6 + [1] * 6,[39m
[38;5;15m            [39m[38;5;242m# pipeline_num_layers=model.cfg.hidden_layers,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mscheduler[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mWarmupExponentialLR[39m[38;5;15m)[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15mwarmup_factor[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mgamma[39m[38;5;197m=[39m[38;5;141m1.0[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_method[39m[38;5;197m=[39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mwarmup_iter[39m[38;5;197m=[39m[38;5;141m0.0[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mevaluation[39m[38;5;197m=[39m[38;5;15mdict[39m[38;5;15m([39m
[38;5;15m            [39m[38;5;15menabled[39m[38;5;197m=[39m[38;5;81mTrue[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15mevaluator[39m[38;5;197m=[39m[38;5;15mLazyCall[39m[38;5;15m([39m[38;5;15mPPLEvaluator[39m[38;5;15m)[39m[38;5;15m([39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_iter[39m[38;5;197m=[39m[38;5;141m250[39m[38;5;15m,[39m
[38;5;15m            [39m[38;5;15meval_period[39m[38;5;197m=[39m[38;5;141m4000[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15m)[39m[38;5;15m,[39m
[38;5;15m        [39m[38;5;15mrdma_enabled[39m[38;5;197m=[39m[38;5;81mFalse[39m[38;5;15m,[39m
[38;5;15m    [39m[38;5;15m)[39m
[38;5;15m)[39m

[04/17 16:45:48] libai INFO: Full config saved to projects/MagicPrompt/oneflow_magicprompt/config.yaml
[04/17 16:45:48] lb.engine.default INFO: > compiling dataset index builder ...
[04/17 16:45:48] lb.engine.default INFO: >>> done with dataset index builder. Compilation time: 0.045 seconds
[04/17 16:45:48] lb.engine.default INFO: >>> done with compiling. Compilation time: 0.046 seconds
[04/17 16:45:50] lb.engine.default INFO: Prepare training, validating, testing set
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: building dataset index ...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: warming up index mmap file...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: reading sizes...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: reading pointers...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: reading document index...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: warming up data mmap file...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: creating numpy buffer of mmap...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: creating memory view of numpy buffer...
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: Finished creating indexed dataset in 0.007694 seconds
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: indexed dataset stats:
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: number of documents: 73718
[04/17 16:45:50] lb.data.data_utils.indexed_dataset INFO: number of sentences: 106365
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_40000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.004 seconds
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 40608
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 9
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_3000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading doc-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_doc_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading sample-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_sample_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:  > loading shuffle-idx mapping from /home/zhangxiaoyu/magicprompt/train/en_train_mmap_text_sentence_gpt-2_indexmap_1000ns_1024sl_1234s_shuffle_idx.npy
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     loaded indexed file in 0.001 seconds
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of samples: 4512
[04/17 16:45:50] lb.data.datasets.gpt_dataset INFO:     total number of epochs: 1
[04/17 16:45:50] lb.engine.default INFO: Auto-scaling the config to train.train_iter=335008, train.warmup_iter=0
[04/17 16:45:50] libai INFO: > Start building model...
[04/17 16:45:50] lb.engine.default INFO: Model:
GPTForPreTraining(
  (GPT_model): GPTModel(
    (embeddings): GPTEmbedding(
      (token_embeddings): VocabEmbedding(num_embeddings=50304, embedding_dim=768)
      (position_embeddings): Embedding(num_embeddings=1024, embedding_dim=768)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layers): ModuleList(
        (0): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): TransformerLayer(
          (drop_path): Identity()
          (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            hidden_size=768, num_heads=12, is_cross_attention=False
            (dropout): Dropout(p=0.1, inplace=False)
            (output_dropout): Dropout(p=0.1, inplace=False)
            (query_key_value): Linear1D(in_features=768, out_features=2304, bias=True, parallel=col)
            (dense): Linear1D(in_features=768, out_features=768, bias=True, parallel=row)
          )
          (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            bias_gelu_fusion=False, bias_dropout_fusion=False, dropout=0.1
            (dense_h_to_4h): Linear1D(in_features=768, out_features=3072, bias=True, parallel=col)
            (activation_func): GeLUTanh()
            (dense_4h_to_h): Linear1D(in_features=3072, out_features=768, bias=True, parallel=row)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (layernorm_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): LMLogits()
  )
  (loss_func): GPTLoss(
    (lm_loss): ParallelCrossEntropyLoss()
  )
)
[04/17 16:45:50] libai INFO: >>> done with building model. Building time: 0.199 seconds
[04/17 16:45:50] lb.scheduler.lr_scheduler WARNING: warmup iters equals to zero, return ExponentialLR
[04/17 16:45:50] lb.engine.trainer INFO: Starting training from iteration 0
[04/17 16:45:51] lb.utils.events INFO:  iteration: 0/335008  consumed_samples: 4  total_loss: 10.86  data_time: 0.0013 s/iter  lr: 5.00e-05  
[04/17 16:45:52] lb.utils.events INFO:  eta: 3 days, 20:51:01  iteration: 1/335008  consumed_samples: 8  total_loss: 10.08  data_time: 0.0012 s/iter  lr: 5.00e-05  
[04/17 16:45:53] lb.utils.events INFO:  eta: 3 days, 21:02:55  iteration: 2/335008  consumed_samples: 12  total_loss: 9.452  time: 0.9999 s/iter  data_time: 0.0011 s/iter total_throughput: 4.00 samples/s lr: 5.00e-05  
[04/17 16:45:54] lb.utils.events INFO:  eta: 3 days, 20:46:14  iteration: 3/335008  consumed_samples: 16  total_loss: 9.38  time: 0.9969 s/iter  data_time: 0.0012 s/iter total_throughput: 4.01 samples/s lr: 5.00e-05  
[04/17 16:45:55] lb.utils.events INFO:  eta: 3 days, 20:37:01  iteration: 4/335008  consumed_samples: 20  total_loss: 9.309  time: 0.9964 s/iter  data_time: 0.0010 s/iter total_throughput: 4.01 samples/s lr: 5.00e-05  
[04/17 16:45:56] lb.utils.events INFO:  eta: 3 days, 20:36:21  iteration: 5/335008  consumed_samples: 24  total_loss: 9.213  time: 0.9960 s/iter  data_time: 0.0012 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:45:57] lb.utils.events INFO:  eta: 3 days, 20:36:59  iteration: 6/335008  consumed_samples: 28  total_loss: 9.118  time: 0.9964 s/iter  data_time: 0.0011 s/iter total_throughput: 4.01 samples/s lr: 5.00e-05  
[04/17 16:45:58] lb.utils.events INFO:  eta: 3 days, 20:43:43  iteration: 7/335008  consumed_samples: 32  total_loss: 9.097  time: 0.9966 s/iter  data_time: 0.0011 s/iter total_throughput: 4.01 samples/s lr: 5.00e-05  
[04/17 16:45:59] lb.utils.events INFO:  eta: 3 days, 20:36:57  iteration: 8/335008  consumed_samples: 36  total_loss: 9.075  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:00] lb.utils.events INFO:  eta: 3 days, 20:43:41  iteration: 9/335008  consumed_samples: 40  total_loss: 8.992  time: 0.9961 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:01] lb.utils.events INFO:  eta: 3 days, 20:40:43  iteration: 10/335008  consumed_samples: 44  total_loss: 8.908  time: 0.9961 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:02] lb.utils.events INFO:  eta: 3 days, 20:44:04  iteration: 11/335008  consumed_samples: 48  total_loss: 8.861  time: 0.9962 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:03] lb.utils.events INFO:  eta: 3 days, 20:40:41  iteration: 12/335008  consumed_samples: 52  total_loss: 8.814  time: 0.9959 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:04] lb.utils.events INFO:  eta: 3 days, 20:38:46  iteration: 13/335008  consumed_samples: 56  total_loss: 8.798  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:05] lb.utils.events INFO:  eta: 3 days, 20:40:39  iteration: 14/335008  consumed_samples: 60  total_loss: 8.781  time: 0.9959 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:06] lb.utils.events INFO:  eta: 3 days, 20:40:06  iteration: 15/335008  consumed_samples: 64  total_loss: 8.747  time: 0.9959 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:07] lb.utils.events INFO:  eta: 3 days, 20:39:33  iteration: 16/335008  consumed_samples: 68  total_loss: 8.712  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:08] lb.utils.events INFO:  eta: 3 days, 20:40:04  iteration: 17/335008  consumed_samples: 72  total_loss: 8.7  time: 0.9959 s/iter  data_time: 0.0011 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:09] lb.utils.events INFO:  eta: 3 days, 20:40:35  iteration: 18/335008  consumed_samples: 76  total_loss: 8.687  time: 0.9960 s/iter  data_time: 0.0011 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:10] lb.utils.events INFO:  eta: 3 days, 20:40:02  iteration: 19/335008  consumed_samples: 80  total_loss: 8.67  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:11] lb.utils.events INFO:  eta: 3 days, 20:40:33  iteration: 20/335008  consumed_samples: 84  total_loss: 8.653  time: 0.9959 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:12] lb.utils.events INFO:  eta: 3 days, 20:40:00  iteration: 21/335008  consumed_samples: 88  total_loss: 8.572  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:13] lb.utils.events INFO:  eta: 3 days, 20:40:31  iteration: 22/335008  consumed_samples: 92  total_loss: 8.491  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:14] lb.utils.events INFO:  eta: 3 days, 20:39:58  iteration: 23/335008  consumed_samples: 96  total_loss: 8.49  time: 0.9958 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:15] lb.utils.events INFO:  eta: 3 days, 20:39:25  iteration: 24/335008  consumed_samples: 100  total_loss: 8.489  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:16] lb.utils.events INFO:  eta: 3 days, 20:39:56  iteration: 25/335008  consumed_samples: 104  total_loss: 8.479  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:17] lb.utils.events INFO:  eta: 3 days, 20:39:23  iteration: 26/335008  consumed_samples: 108  total_loss: 8.468  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:18] lb.utils.events INFO:  eta: 3 days, 20:38:00  iteration: 27/335008  consumed_samples: 112  total_loss: 8.463  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:19] lb.utils.events INFO:  eta: 3 days, 20:37:17  iteration: 28/335008  consumed_samples: 116  total_loss: 8.458  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:20] lb.utils.events INFO:  eta: 3 days, 20:38:18  iteration: 29/335008  consumed_samples: 120  total_loss: 8.407  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:21] lb.utils.events INFO:  eta: 3 days, 20:37:15  iteration: 30/335008  consumed_samples: 124  total_loss: 8.355  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:22] lb.utils.events INFO:  eta: 3 days, 20:36:54  iteration: 31/335008  consumed_samples: 128  total_loss: 8.342  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:23] lb.utils.events INFO:  eta: 3 days, 20:37:13  iteration: 32/335008  consumed_samples: 132  total_loss: 8.329  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:24] lb.utils.events INFO:  eta: 3 days, 20:36:52  iteration: 33/335008  consumed_samples: 136  total_loss: 8.318  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:25] lb.utils.events INFO:  eta: 3 days, 20:37:11  iteration: 34/335008  consumed_samples: 140  total_loss: 8.307  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:26] lb.utils.events INFO:  eta: 3 days, 20:36:50  iteration: 35/335008  consumed_samples: 144  total_loss: 8.305  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:27] lb.utils.events INFO:  eta: 3 days, 20:36:29  iteration: 36/335008  consumed_samples: 148  total_loss: 8.304  time: 0.9955 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:28] lb.utils.events INFO:  eta: 3 days, 20:36:48  iteration: 37/335008  consumed_samples: 152  total_loss: 8.215  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:29] lb.utils.events INFO:  eta: 3 days, 20:37:07  iteration: 38/335008  consumed_samples: 156  total_loss: 8.126  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:30] lb.utils.events INFO:  eta: 3 days, 20:37:15  iteration: 39/335008  consumed_samples: 160  total_loss: 8.111  time: 0.9955 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:31] lb.utils.events INFO:  eta: 3 days, 20:37:23  iteration: 40/335008  consumed_samples: 164  total_loss: 8.095  time: 0.9955 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:32] lb.utils.events INFO:  eta: 3 days, 20:37:13  iteration: 41/335008  consumed_samples: 168  total_loss: 8.091  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:33] lb.utils.events INFO:  eta: 3 days, 20:37:03  iteration: 42/335008  consumed_samples: 172  total_loss: 8.087  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:34] lb.utils.events INFO:  eta: 3 days, 20:37:11  iteration: 43/335008  consumed_samples: 176  total_loss: 8.063  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:35] lb.utils.events INFO:  eta: 3 days, 20:37:01  iteration: 44/335008  consumed_samples: 180  total_loss: 8.04  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:36] lb.utils.events INFO:  eta: 3 days, 20:37:09  iteration: 45/335008  consumed_samples: 184  total_loss: 8.01  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:37] lb.utils.events INFO:  eta: 3 days, 20:37:17  iteration: 46/335008  consumed_samples: 188  total_loss: 7.98  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:38] lb.utils.events INFO:  eta: 3 days, 20:37:07  iteration: 47/335008  consumed_samples: 192  total_loss: 7.949  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:39] lb.utils.events INFO:  eta: 3 days, 20:37:15  iteration: 48/335008  consumed_samples: 196  total_loss: 7.918  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:40] lb.utils.events INFO:  eta: 3 days, 20:37:05  iteration: 49/335008  consumed_samples: 200  total_loss: 7.886  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:41] lb.utils.events INFO:  eta: 3 days, 20:37:13  iteration: 50/335008  consumed_samples: 204  total_loss: 7.854  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:42] lb.utils.events INFO:  eta: 3 days, 20:37:03  iteration: 51/335008  consumed_samples: 208  total_loss: 7.851  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:43] lb.utils.events INFO:  eta: 3 days, 20:37:11  iteration: 52/335008  consumed_samples: 212  total_loss: 7.847  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:44] lb.utils.events INFO:  eta: 3 days, 20:37:08  iteration: 53/335008  consumed_samples: 216  total_loss: 7.841  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:45] lb.utils.events INFO:  eta: 3 days, 20:37:05  iteration: 54/335008  consumed_samples: 220  total_loss: 7.834  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:46] lb.utils.events INFO:  eta: 3 days, 20:37:06  iteration: 55/335008  consumed_samples: 224  total_loss: 7.792  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:47] lb.utils.events INFO:  eta: 3 days, 20:37:03  iteration: 56/335008  consumed_samples: 228  total_loss: 7.75  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:48] lb.utils.events INFO:  eta: 3 days, 20:36:55  iteration: 57/335008  consumed_samples: 232  total_loss: 7.705  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:49] lb.utils.events INFO:  eta: 3 days, 20:37:01  iteration: 58/335008  consumed_samples: 236  total_loss: 7.66  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:50] lb.utils.events INFO:  eta: 3 days, 20:37:02  iteration: 59/335008  consumed_samples: 240  total_loss: 7.658  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:51] lb.utils.events INFO:  eta: 3 days, 20:36:59  iteration: 60/335008  consumed_samples: 244  total_loss: 7.657  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:52] lb.utils.events INFO:  eta: 3 days, 20:36:51  iteration: 61/335008  consumed_samples: 248  total_loss: 7.652  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:53] lb.utils.events INFO:  eta: 3 days, 20:36:43  iteration: 62/335008  consumed_samples: 252  total_loss: 7.648  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:54] lb.utils.events INFO:  eta: 3 days, 20:36:49  iteration: 63/335008  consumed_samples: 256  total_loss: 7.628  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:55] lb.utils.events INFO:  eta: 3 days, 20:36:55  iteration: 64/335008  consumed_samples: 260  total_loss: 7.608  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:56] lb.utils.events INFO:  eta: 3 days, 20:36:47  iteration: 65/335008  consumed_samples: 264  total_loss: 7.562  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:57] lb.utils.events INFO:  eta: 3 days, 20:36:39  iteration: 66/335008  consumed_samples: 268  total_loss: 7.517  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:58] lb.utils.events INFO:  eta: 3 days, 20:36:45  iteration: 67/335008  consumed_samples: 272  total_loss: 7.516  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:46:59] lb.utils.events INFO:  eta: 3 days, 20:36:37  iteration: 68/335008  consumed_samples: 276  total_loss: 7.514  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:00] lb.utils.events INFO:  eta: 3 days, 20:36:16  iteration: 69/335008  consumed_samples: 280  total_loss: 7.482  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:01] lb.utils.events INFO:  eta: 3 days, 20:35:55  iteration: 70/335008  consumed_samples: 284  total_loss: 7.45  time: 0.9954 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:02] lb.utils.events INFO:  eta: 3 days, 20:36:14  iteration: 71/335008  consumed_samples: 288  total_loss: 7.446  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:03] lb.utils.events INFO:  eta: 3 days, 20:35:53  iteration: 72/335008  consumed_samples: 292  total_loss: 7.442  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:04] lb.utils.events INFO:  eta: 3 days, 20:35:50  iteration: 73/335008  consumed_samples: 296  total_loss: 7.412  time: 0.9954 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:05] lb.utils.events INFO:  eta: 3 days, 20:35:51  iteration: 74/335008  consumed_samples: 300  total_loss: 7.382  time: 0.9955 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:06] lb.utils.events INFO:  eta: 3 days, 20:36:10  iteration: 75/335008  consumed_samples: 304  total_loss: 7.38  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:07] lb.utils.events INFO:  eta: 3 days, 20:36:29  iteration: 76/335008  consumed_samples: 308  total_loss: 7.378  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:08] lb.utils.events INFO:  eta: 3 days, 20:36:08  iteration: 77/335008  consumed_samples: 312  total_loss: 7.369  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:09] lb.utils.events INFO:  eta: 3 days, 20:36:27  iteration: 78/335008  consumed_samples: 316  total_loss: 7.361  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:10] lb.utils.events INFO:  eta: 3 days, 20:36:06  iteration: 79/335008  consumed_samples: 320  total_loss: 7.343  time: 0.9955 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:11] lb.utils.events INFO:  eta: 3 days, 20:36:25  iteration: 80/335008  consumed_samples: 324  total_loss: 7.324  time: 0.9955 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:12] lb.utils.events INFO:  eta: 3 days, 20:36:04  iteration: 81/335008  consumed_samples: 328  total_loss: 7.307  time: 0.9955 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:13] lb.utils.events INFO:  eta: 3 days, 20:35:43  iteration: 82/335008  consumed_samples: 332  total_loss: 7.29  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:14] lb.utils.events INFO:  eta: 3 days, 20:35:40  iteration: 83/335008  consumed_samples: 336  total_loss: 7.288  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:15] lb.utils.events INFO:  eta: 3 days, 20:35:41  iteration: 84/335008  consumed_samples: 340  total_loss: 7.286  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:16] lb.utils.events INFO:  eta: 3 days, 20:36:00  iteration: 85/335008  consumed_samples: 344  total_loss: 7.242  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:17] lb.utils.events INFO:  eta: 3 days, 20:36:19  iteration: 86/335008  consumed_samples: 348  total_loss: 7.199  time: 0.9955 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:18] lb.utils.events INFO:  eta: 3 days, 20:36:25  iteration: 87/335008  consumed_samples: 352  total_loss: 7.15  time: 0.9955 s/iter  data_time: 0.0008 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:19] lb.utils.events INFO:  eta: 3 days, 20:36:31  iteration: 88/335008  consumed_samples: 356  total_loss: 7.101  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:20] lb.utils.events INFO:  eta: 3 days, 20:36:32  iteration: 89/335008  consumed_samples: 360  total_loss: 7.082  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:21] lb.utils.events INFO:  eta: 3 days, 20:36:33  iteration: 90/335008  consumed_samples: 364  total_loss: 7.062  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:22] lb.utils.events INFO:  eta: 3 days, 20:36:35  iteration: 91/335008  consumed_samples: 368  total_loss: 7.036  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:23] lb.utils.events INFO:  eta: 3 days, 20:36:31  iteration: 92/335008  consumed_samples: 372  total_loss: 7.01  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:24] lb.utils.events INFO:  eta: 3 days, 20:36:33  iteration: 93/335008  consumed_samples: 376  total_loss: 6.996  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:25] lb.utils.events INFO:  eta: 3 days, 20:36:29  iteration: 94/335008  consumed_samples: 380  total_loss: 6.983  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:26] lb.utils.events INFO:  eta: 3 days, 20:36:31  iteration: 95/335008  consumed_samples: 384  total_loss: 6.963  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:27] lb.utils.events INFO:  eta: 3 days, 20:36:27  iteration: 96/335008  consumed_samples: 388  total_loss: 6.942  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:28] lb.utils.events INFO:  eta: 3 days, 20:36:29  iteration: 97/335008  consumed_samples: 392  total_loss: 6.924  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:29] lb.utils.events INFO:  eta: 3 days, 20:36:25  iteration: 98/335008  consumed_samples: 396  total_loss: 6.905  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:30] lb.utils.events INFO:  eta: 3 days, 20:36:27  iteration: 99/335008  consumed_samples: 400  total_loss: 6.86  time: 0.9956 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:31] lb.utils.events INFO:  eta: 3 days, 20:36:29  iteration: 100/335008  consumed_samples: 404  total_loss: 6.815  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:32] lb.utils.events INFO:  eta: 3 days, 20:36:25  iteration: 101/335008  consumed_samples: 408  total_loss: 6.808  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:33] lb.utils.events INFO:  eta: 3 days, 20:36:21  iteration: 102/335008  consumed_samples: 412  total_loss: 6.8  time: 0.9956 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:34] lb.utils.events INFO:  eta: 3 days, 20:36:23  iteration: 103/335008  consumed_samples: 416  total_loss: 6.787  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:35] lb.utils.events INFO:  eta: 3 days, 20:36:19  iteration: 104/335008  consumed_samples: 420  total_loss: 6.774  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:36] lb.utils.events INFO:  eta: 3 days, 20:36:21  iteration: 105/335008  consumed_samples: 424  total_loss: 6.767  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:37] lb.utils.events INFO:  eta: 3 days, 20:36:23  iteration: 106/335008  consumed_samples: 428  total_loss: 6.76  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:38] lb.utils.events INFO:  eta: 3 days, 20:36:43  iteration: 107/335008  consumed_samples: 432  total_loss: 6.717  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:39] lb.utils.events INFO:  eta: 3 days, 20:36:21  iteration: 108/335008  consumed_samples: 436  total_loss: 6.673  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:40] lb.utils.events INFO:  eta: 3 days, 20:36:41  iteration: 109/335008  consumed_samples: 440  total_loss: 6.659  time: 0.9957 s/iter  data_time: 0.0009 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:41] lb.utils.events INFO:  eta: 3 days, 20:36:19  iteration: 110/335008  consumed_samples: 444  total_loss: 6.645  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:42] lb.utils.events INFO:  eta: 3 days, 20:36:39  iteration: 111/335008  consumed_samples: 448  total_loss: 6.59  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:43] lb.utils.events INFO:  eta: 3 days, 20:36:17  iteration: 112/335008  consumed_samples: 452  total_loss: 6.534  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:44] lb.utils.events INFO:  eta: 3 days, 20:36:37  iteration: 113/335008  consumed_samples: 456  total_loss: 6.522  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:45] lb.utils.events INFO:  eta: 3 days, 20:36:15  iteration: 114/335008  consumed_samples: 460  total_loss: 6.51  time: 0.9957 s/iter  data_time: 0.0010 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:46] lb.utils.events INFO:  eta: 3 days, 20:36:11  iteration: 115/335008  consumed_samples: 464  total_loss: 6.486  time: 0.9956 s/iter  data_time: 0.0011 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:47] lb.utils.events INFO:  eta: 3 days, 20:36:13  iteration: 116/335008  consumed_samples: 468  total_loss: 6.461  time: 0.9957 s/iter  data_time: 0.0011 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
[04/17 16:47:48] lb.utils.events INFO:  eta: 3 days, 20:36:09  iteration: 117/335008  consumed_samples: 472  total_loss: 6.459  time: 0.9956 s/iter  data_time: 0.0011 s/iter total_throughput: 4.02 samples/s lr: 5.00e-05  
